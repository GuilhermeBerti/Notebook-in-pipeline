# ğŸ“Œ Projeto: Uso de Notebooks do Spark em Pipelines de Dados no Azure
## ğŸ“– DescriÃ§Ã£o

Este projeto demonstra como integrar e executar notebooks do Apache Spark dentro de pipelines do Azure Synapse Analytics, aplicando conceitos de Engenharia de Dados em escala corporativa.
O objetivo principal Ã© automatizar o processamento de dados distribuÃ­dos, utilizando Azure Synapse Pipelines para orquestrar tarefas de ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise em notebooks Spark.

## ğŸ”‘ Principais Funcionalidades

IntegraÃ§Ã£o com Azure Synapse Analytics: execuÃ§Ã£o de notebooks Spark diretamente em pipelines.
OrquestraÃ§Ã£o de tarefas: uso de atividades de notebook no pipeline para garantir automaÃ§Ã£o e escalabilidade.
TransformaÃ§Ã£o de dados em larga escala: processamento distribuÃ­do com Spark, aproveitando clusters de pools Spark no Synapse.
Gerenciamento de dependÃªncias: controle de variÃ¡veis e parÃ¢metros entre cÃ©lulas e atividades do pipeline.
Armazenamento otimizado: uso de formatos como Parquet e Delta Lake para alta performance em consultas analÃ­ticas.

## âš™ï¸ Tecnologias Utilizadas

Azure Synapse Analytics (Pipelines + Pools Spark)
Apache Spark
Parquet / Delta Lake
Python / PySpark

## ğŸ¯ Objetivo do Projeto

Exemplificar uma abordagem prÃ¡tica e escalÃ¡vel para engenharia de dados em nuvem, permitindo que pipelines do Synapse orquestrem a execuÃ§Ã£o de notebooks Spark de forma automatizada e integrada, reduzindo esforÃ§o manual e acelerando processos de anÃ¡lise.
